{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pysolr datasets openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Fashion dataset from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load the dataset from huggingface datasets hub\n",
    "fashion = load_dataset(\n",
    "    \"ashraq/fashion-product-images-small\",\n",
    "    split=\"train\"\n",
    ")\n",
    "fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to be able to disply images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "from io import BytesIO\n",
    "from base64 import b64encode\n",
    "\n",
    "# function to display product images\n",
    "def display_result(image_batch):\n",
    "    figures = []\n",
    "    for img in image_batch:\n",
    "        b = BytesIO()  \n",
    "        img.save(b, format='png')\n",
    "        figures.append(f'''\n",
    "            <figure style=\"margin: 5px !important;\">\n",
    "              <img src=\"data:image/png;base64,{b64encode(b.getvalue()).decode('utf-8')}\" style=\"width: 90px; height: 120px\" >\n",
    "            </figure>\n",
    "        ''')\n",
    "    return HTML(data=f'''\n",
    "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
    "        {''.join(figures)}\n",
    "        </div>\n",
    "    ''')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assign the images and metadata to separate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = fashion[\"image\"]\n",
    "metadata = fashion.remove_columns(\"image\")\n",
    "metadata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_result(images[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert metadata into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = metadata.to_pandas()\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data enrichment for solr records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Install the OpenAI library if you haven't already: pip install openai\n",
    "# Replace \"your_api_key_here\" with your actual OpenAI API key\n",
    "openai.api_key = 'sk-replaceme!!!!'\n",
    "\n",
    "# Create a sample DataFrame named 'metadata'\n",
    "data = metadata\n",
    "metadata = pd.DataFrame(data)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries for Solr\n",
    "documents = metadata.to_dict(orient='records')\n",
    "\n",
    "\n",
    "def prepare_prompt(product_json):\n",
    "    prompt = f\"Create a product description for this:\\n{product_json}\"\n",
    "    return prompt\n",
    "\n",
    "def generate_description(prompt):\n",
    "    max_retries = 5\n",
    "    for retry_count in range(max_retries):\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=\"text-davinci-003\",\n",
    "                prompt=prompt,\n",
    "                max_tokens=256,\n",
    "                n=1,\n",
    "                stop=None,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            return response.choices[0].text.strip()\n",
    "        except Exception as e:\n",
    "            # If an error occurs, wait for an increasing amount of time before retrying\n",
    "            sleep_time = 2 ** retry_count\n",
    "            print(f\"Error occurred: {e}, retrying in {sleep_time} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "    raise Exception(\"Exceeded maximum retries for generate_description\")\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    for i, document in enumerate(documents):\n",
    "        prompt = prepare_prompt(json.dumps(document))\n",
    "        description = generate_description(prompt)\n",
    "        document[\"description\"] = description\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            with open(f'store.pickle', 'wb') as f:\n",
    "                pickle.dump(documents, f)\n",
    "\n",
    "    for document in documents:\n",
    "        print(document)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only do 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Install the OpenAI library if you haven't already: pip install openai\n",
    "# Replace \"your_api_key_here\" with your actual OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Create a sample DataFrame named 'metadata'\n",
    "data = metadata\n",
    "metadata = pd.DataFrame(data)\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries for Solr\n",
    "documents = metadata.to_dict(orient='records')\n",
    "\n",
    "\n",
    "def prepare_prompt(product_json):\n",
    "    prompt = f\"Create a product description for this:\\n{product_json}\"\n",
    "    return prompt\n",
    "\n",
    "def generate_description(prompt):\n",
    "    max_retries = 5\n",
    "    for retry_count in range(max_retries):\n",
    "        try:\n",
    "            response = openai.Completion.create(\n",
    "                engine=\"text-davinci-003\",\n",
    "                prompt=prompt,\n",
    "                max_tokens=256,\n",
    "                n=1,\n",
    "                stop=None,\n",
    "                temperature=0.7,\n",
    "            )\n",
    "            return response.choices[0].text.strip()\n",
    "        except Exception as e:\n",
    "            # If an error occurs, wait for an increasing amount of time before retrying\n",
    "            sleep_time = 2 ** retry_count\n",
    "            print(f\"Error occurred: {e}, retrying in {sleep_time} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "    raise Exception(\"Exceeded maximum retries for generate_description\")\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    prompt = prepare_prompt(json.dumps(documents[0]))\n",
    "    description = generate_description(prompt)\n",
    "    documents[0][\"description\"] = description\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "wrapped_text = textwrap.fill(documents[0][\"description\"], width=50)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Pickle the array\n",
    "with open('store.pickle', 'wb') as f:\n",
    "    pickle.dump(documents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Read the pickle file\n",
    "with open('store.pickle', 'rb') as f:\n",
    "    vector_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pysolr to write records to a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysolr\n",
    "\n",
    "# Connect to the local Solr instance\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/store', always_commit=True)\n",
    "\n",
    "# Write the documents to the Solr collection\n",
    "solr.add(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a navigational tree of the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# create a sample dataframe\n",
    "df = metadata\n",
    "\n",
    "# create a defaultdict to store the hierarchical tree\n",
    "tree = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "# iterate through the dataframe and add to the tree\n",
    "for _, row in df.iterrows():\n",
    "    master_cat = row['masterCategory']\n",
    "    sub_cat = row['subCategory']\n",
    "    article_type = row['articleType']\n",
    "    tree[master_cat][sub_cat].add(article_type)\n",
    "\n",
    "# print the tree\n",
    "for master_cat, sub_cats in tree.items():\n",
    "    print(master_cat)\n",
    "    for sub_cat, article_types in sub_cats.items():\n",
    "        print('\\t', sub_cat)\n",
    "        for article_type in article_types:\n",
    "            print('\\t\\t', article_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
